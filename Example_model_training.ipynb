{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from custom_ml_toolkit.preprocessor.encoder import SupportMissingDatasetEncoder\n",
    "from custom_ml_toolkit.feature_selector.importance_explaner import plot_feature_importances, plot_shap_values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 77\n",
    "\n",
    "data_df = pd.read_csv('example_data/titanic.csv')\n",
    "data_df['Deck'] = data_df['Cabin'].str[0]\n",
    "\n",
    "numerical_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "norminal_cols = ['Sex', 'Embarked']\n",
    "ordinal_cols = ['Pclass', 'Deck']\n",
    "target_col = 'Survived'\n",
    "\n",
    "train_data_df, test_data_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.2,\n",
    "    random_state=random_state,\n",
    "    stratify=data_df['Survived']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = SupportMissingDatasetEncoder(\n",
    "    numerical_cols=numerical_cols,\n",
    "    norminal_cols=norminal_cols,\n",
    "    ordinal_cols=ordinal_cols,\n",
    "    target_col=target_col,\n",
    "    drop_binary=True,\n",
    "    oe_unknown_value=np.nan,\n",
    "    oe_missing_value=np.nan,\n",
    "    encode_target=True\n",
    ")\n",
    "\n",
    "de.fit(train_data_df)\n",
    "encoded_train_data_df = de.transform(train_data_df)\n",
    "encoded_test_data_df = de.transform(test_data_df)\n",
    "\n",
    "clf = XGBClassifier(\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "X_train = encoded_train_data_df.drop(columns=['Survived'])\n",
    "y_train = encoded_train_data_df['Survived']\n",
    "\n",
    "X_test = encoded_test_data_df.drop(columns=['Survived'])\n",
    "y_test = encoded_test_data_df['Survived']\n",
    "\n",
    "clf.fit(\n",
    "    X=X_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "feat_imp_df = plot_feature_importances(\n",
    "    feature_importance=clf.feature_importances_,\n",
    "    feature_names=X_train.columns,\n",
    "    top_n=30\n",
    ")\n",
    "\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "\n",
    "# explainer = shap.TreeExplainer(clf)\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# shap.summary_plot(\n",
    "#     shap_values=shap_values,\n",
    "#     features=X_train,\n",
    "#     plot_type='bar',\n",
    "#     show=False\n",
    "# )\n",
    "# # shap.plots.waterfall(shap_values[3])\n",
    "\n",
    "# shap_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = SupportMissingDatasetEncoder(\n",
    "    numerical_cols=numerical_cols,\n",
    "    norminal_cols=None,\n",
    "    ordinal_cols=norminal_cols + ordinal_cols,\n",
    "    target_col=target_col,\n",
    "    drop_binary=True,\n",
    "    oe_unknown_value=-1,\n",
    "    oe_missing_value=-1,\n",
    "    encode_target=False\n",
    ")\n",
    "\n",
    "de.fit(train_data_df)\n",
    "encoded_train_data_df = de.transform(train_data_df)\n",
    "encoded_test_data_df = de.transform(test_data_df)\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "X_train = encoded_train_data_df.drop(columns=['Survived'])\n",
    "y_train = encoded_train_data_df['Survived']\n",
    "\n",
    "X_test = encoded_test_data_df.drop(columns=['Survived'])\n",
    "y_test = encoded_test_data_df['Survived']\n",
    "\n",
    "clf.fit(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    categorical_feature=norminal_cols\n",
    ")\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "feat_imp_df = plot_feature_importances(\n",
    "    feature_importance=clf.feature_importances_,\n",
    "    feature_names=X_train.columns,\n",
    "    top_n=30\n",
    ")\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = SupportMissingDatasetEncoder(\n",
    "    numerical_cols=numerical_cols,\n",
    "    norminal_cols=norminal_cols,\n",
    "    ordinal_cols=ordinal_cols,\n",
    "    target_col=target_col,\n",
    "    drop_binary=True,\n",
    "    oe_unknown_value=np.nan,\n",
    "    oe_missing_value=np.nan,\n",
    "    encode_target=False\n",
    ")\n",
    "\n",
    "de.fit(data_df)\n",
    "encoded_data_df = de.transform(data_df)\n",
    "\n",
    "norminal_feature_name_out = de.features_encoder.get_norminal_feature_name_out()\n",
    "encoded_data_df[numerical_cols + ordinal_cols] = encoded_data_df[numerical_cols + ordinal_cols].fillna(-999)\n",
    "encoded_data_df[norminal_feature_name_out] = encoded_data_df[norminal_feature_name_out].fillna(0)\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    random_state=random_state,\n",
    "    # max_depth=15\n",
    ")\n",
    "\n",
    "X_train = encoded_data_df.drop(columns=['Survived'])\n",
    "y_train = encoded_data_df['Survived']\n",
    "\n",
    "clf.fit(\n",
    "    X=X_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# plt.figure(figsize=(300,50))\n",
    "# plt.figure(figsize=(100,50))\n",
    "# plot_tree(\n",
    "#     decision_tree=clf,\n",
    "#     feature_names=X_train.columns,\n",
    "#     class_names=de.classes_,\n",
    "#     filled=True,\n",
    "#     fontsize=6\n",
    "# )\n",
    "# plt.savefig(\n",
    "#     fname ='tree_high_dpi',\n",
    "#     dpi=100\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
